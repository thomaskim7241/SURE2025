library(tidyverse)
library(factoextra)
library(ggplot2)
library(ggmosaic)
library(readr)
dataset_names <- names(read.csv("analytic_data2025_v2.csv"))
dataset <- read.csv("analytic_data2025_v2.csv", skip = 1,header = T)
names(dataset) = dataset_names
view(dataset)

#changing dots/spaces to underscores
install.packages('janitor')
library(janitor)
dataset_clean <- clean_names(dataset)
view(dataset_clean)

#removing a duplicate row
dataset_clean <- dataset[-1, ]
view(dataset_clean)

#picking keywords, grabbing columns with them then subsetting a new dataset
keywords <- c("state", "name", "death", "overdose", "drug", "mental", "suicide", 
              "housing", "pollution", "air", "poverty", "unemployment", 
              "access", "insurance", "healthcare", "mental", "premature", 
              "AIAN", "Native", "health", "physical", "poor", "college",
              "age", "drug", "mortality", "care", "ratio", "insured", 
              "race", "Black", "White", "Hispanic", "Latino", 
              "Asian", "AIAN", "American.Indian", "Alaska.Native", 
              "Native", "Pacific", "alcohol")

#converting all values to numeric
filtered_data_clean <- filtered_data %>%
  mutate(across(
    .cols = everything(),
    .fns = ~ suppressWarnings(as.numeric(gsub(",", "", .)))
  ))
clean_data <- numeric_data %>%
  drop_na()
numeric_data_clean <- numeric_data %>%
  select(where(~ !all(is.na(.)) && sd(., na.rm = TRUE) != 0))
numeric_data_clean <- filtered_data_clean %>% select(where(is.numeric))
cor_matrix <- cor(numeric_data_clean, use = "pairwise.complete.obs")


#doing a correlation
numeric_data <- dataset_clean |>
  select(where(is.numeric))
sapply(filtered_data, class)


numeric_data <- filtered_data |>
  select(drug_overdose_deaths_raw_value, mental_health_providers_raw_value,
         unemployment_raw_value)

cor_matrix <-
  cor(numeric_data, use = "pairwise.complete.obs")

cor_matrix["X..American.Indian.or.Alaska.Native.raw.value", ] |>
  sort(decreasing = TRUE)
dim(numeric_data)   
install.packages("Hmisc")
library(Hmisc)
cor_results <- rcorr(as.matrix(numeric_data_clean), type = "pearson")

ggplot(mn_data, aes(x = 'X..American.Indian.or.Alaska.Native.raw.value',
               y = 'Alcohol.Impaired.Driving.Deaths', 
               color = 'State.Abbreviation')) +
  geom_point(alpha = 0.7, size = 3) +
  labs(title = "AIAN Raw Value vs Alcohol Impaired Driving Deaths by State",
       x = "AIAN Raw Value",
       y = "Alcohol Impaired Driving Deaths") +
  theme_minimal()

#doing correlations 
numeric_data <- filtered_data |>
  select(drug_overdose_deaths_raw_value, mental_health_providers_raw_value,
         unemployment_raw_value, drug_overdose_deaths_aian, drug_overdose_deaths_black,
         primary_care_physicians_raw_value, ratio_of_population_to_primary_care_physicians,
         uninsured_raw_value, severe_housing_problems_raw_value, children_in_poverty_aian)

cor_matrix <-
  cor(numeric_data, use = "pairwise.complete.obs")
cor_matrix

model <- lm(drug_overdose_deaths_raw_value ~ premature_death_raw_value + 
   mental_health_providers_raw_value,
   data = filtered_data)
summary(model)

ggplot(top_states, aes(x = State, y = TotalClaims, fill = SpecialtyCateg)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ SpecialtyCateg, scales = 'free_y') +
  theme_minimal() +
  labs(
    title = "Top 5 States by Opioid Claims Within Each Specialty",
    x = "State",
    y = "Total Opioid Claims"
  )


lm(Drug_Deaths ~ Poverty_Rate + Mental_Health_Access, data = my_data)

#trying log function
logit_data <- dataset_clean |>
  mutate(across(where(is.numeric), ~ log(.x / (1 - .x))))

library(tidyverse)
library(factoextra)
library(ggplot2)
library(ggmosaic)
library(maps)
library(scales)
library(biscale)
library(cowplot)
library(usmap)
library(GGally)
library(car)
library(broom)
library(dplyr)
setwd("~/Documents/Rstudios/SURE 2025/SURE2025/Kim")
df <- read.csv("analytic_data2025_v2.csv")
df_state <- df %>%
  filter(County.FIPS.Code == "000" & 
           State.FIPS.Code != "00" & 
           Name != "District of Columbia") %>% 
  select(Name, 
         X..Rural.raw.value, 
         Unemployment.raw.value,
         X..Below.18.Years.of.Age.raw.value, 
         Severe.Housing.Problems.raw.value,
         Alcohol.Impaired.Driving.Deaths.raw.value,
         Drug.Overdose.Deaths.raw.value) %>% 
  rename(
    State = Name,
    Rural = X..Rural.raw.value,
    Unemployment = Unemployment.raw.value,
    Youth = X..Below.18.Years.of.Age.raw.value,
    HousingProblems = Severe.Housing.Problems.raw.value,
    ADD =  Alcohol.Impaired.Driving.Deaths.raw.value,
    Drug_OD = Drug.Overdose.Deaths.raw.value
  ) %>%
  mutate(across(c(Rural, Unemployment, Youth, HousingProblems, ADD,
                  Drug_OD), as.numeric),
         State = as.factor(State))
view(df_state)

logit_data <- df_state |>
  mutate(across(where(is.numeric), ~ log(Rural / (1 - Rural))))
df_state <- df_state %>%
  mutate(rural_logit = log(rural / (1 - rural)))

#doing a lasso 
install.packages("glmnet")
library(glmnet)
X <- model.matrix(Drug_OD~ Rural + State + Unemployment + Youth + HousingProblems +
                    ADD, data = df_state)[, -1]
y <- df_state$Drug_OD
lasso_model <- glmnet(X, y, alpha = 1)
plot(lasso_model, xvar = "lambda", label = TRUE)
#cross validation lasso 
cv_lasso <- cv.glmnet(X, y, alpha = 1)
plot(cv_lasso)

accurate <- cv_lasso$lambda.min   # Most accurate
simple <-cv_lasso$lambda.1se #most simple
acc_model <- glmnet(X, y, alpha = 1, lambda = accurate)
sim_model <- final_model <- glmnet(X, y, alpha = 1, lambda = simple)

coef(acc_model)
coeg(sim_model)

#refitting
dataset_name <- dataset_clean |>
  select( 
         X..Rural.raw.value, 
         Unemployment.raw.value,
         X..Below.18.Years.of.Age.raw.value, 
         Severe.Housing.Problems.raw.value,
         Alcohol.Impaired.Driving.Deaths.raw.value,
         Drug.Overdose.Deaths.raw.value) %>% 
  rename(
    Rural = X..Rural.raw.value,
    Unemployment = Unemployment.raw.value,
    Youth = X..Below.18.Years.of.Age.raw.value,
    HousingProblems = Severe.Housing.Problems.raw.value,
    ADD =  Alcohol.Impaired.Driving.Deaths.raw.value,
    Drug_OD = Drug.Overdose.Deaths.raw.value
  )
dataset_log <- dataset_name |>
  mutate(
    logit_ADD = logit(ADD, adjust = 0.001),
  )
view(dataset_log)
# 
# model_logit_ADD <- lm(logit_ADD ~ Rural + Unemployment +
#                        Youth + HousingProblems, data = dataset_log)
model_logit_ADD <- lm(logit_ADD ~ Rural + Unemployment +
                        Youth + HousingProblems, data = df.sub)
summary(model_logit_ADD)

gan_fit1 <- gam(logit_ADD ~ Rural + Unemployment +
                 Youth + HousingProblems, family = scat, data = df.sub)
summary(gan_fit1)

gan_fit2 <- gam(logit_ADD ~ Rural + s(Unemployment) +
                  s(Youth) + s(HousingProblems), family = scat, data = df.sub)
summary(gan_fit2)
##########################
#### residual plots
# Extracting residuals
pearson_residuals <- residuals(model_logit_ADD, type = "pearson")
raw_residuals <- residuals(model_logit_ADD, type = "response")

# Extracting fitted values
fitted_values <- fitted(model_logit_ADD)

# Creating a data frame for ggplot
residuals_df <- data.frame(
  fitted = fitted_values,
  pearson_residuals = pearson_residuals,
  raw_residuals = raw_residuals
)

# Pearson residuals plot
ggplot(residuals_df, aes(x = fitted, y = pearson_residuals)) +
  geom_point()

qqnorm(residuals_df$pearson_residuals)

#partial residual plot, log, exponential, cubed

#partial residual plot
library(car)
crPlots(model_logit_ADD)
summary(model_logit_ADD)
# Basic diagnostic plots
par(mfrow = c(2, 2))
plot(model_logit_ADD)

#log transformation
model_log <- lm(logit_ADD ~ Rural + log(Unemployment + 1) +
                  log(Youth + 1) + log(HousingProblems + 1), data = dataset_log)
crPlots(model_log)
summary(model_log)

#squared
model_poly <- lm(logit_ADD ~ (Rural) + poly(Unemployment, 2) +
                   poly(Youth, 2) + poly(HousingProblems, 2), 
                 data = na.omit(dataset_log))
crPlots(model_poly)
summary(model_poly)

indices.large.standard.residuals <- which(abs(rstandard(model_logit_ADD)) > 3)
indices.large.studentized.residuals <- which(abs(rstudent(model_logit_ADD)) > 3)
length(indices.large.standard.residuals)
length(indices.large.studentized.residuals)
all(indices.large.standard.residuals == indices.large.studentized.residualsdistan

## cook distance
which(cooks.distance(model_logit_ADD) > 4/nrow(dataset_log))

install.packages('mgcv')


# Load package
library(MASS)

# Fit Huber/robust regression model
model_huber <- rlm(logit_ADD ~ Rural + Unemployment + Youth + HousingProblems, data = df.sub)

# Summary
summary(model_huber)



#we shifted to neg infinity to ifinity range to fit a linear framework in order to do our diagnostic
#start with telling how we chose variables, multicolinarity, show mcr test results that say missing values dont matter
#show residual and qq to support outliers not being accounted. the outliers make the noise heavy tail
#go into mlr 
#show partial residual plots
